{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stemming with Python and NLTK.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoSZYiG+h2EHIkDFj0PR4x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranjalpandey22/Natural-Language-Processing/blob/main/Basics/Stemming%20with%20Python%20and%20NLTK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q93IfcntvHim"
      },
      "source": [
        "# Stemming in Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHzk08kSKVYX"
      },
      "source": [
        "If we have textual data, we have to perform a series of text preprocessing techniques to get to that stage. Questions like which techniques to use and when to use them in the process might have answers dependent on the problem you are trying to solve but they all follow something similar to this -\r\n",
        "\r\n",
        "*   Lowercase\r\n",
        "*   Remove unnecessary strings (Problem-dependent)\r\n",
        "*   Tokenization\r\n",
        "*   Remove Stopwords (optional)\r\n",
        "*   Stemming / Lemmatization / Both\r\n",
        "*   Feature Encoding using Lexicon/Vocabulary \r\n",
        "\r\n",
        "## Stemming\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZbKtrKJvEYN"
      },
      "source": [
        "# importing the libraries\r\n",
        "\r\n",
        "import re\r\n",
        "import pandas as pd\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xETEggEN_enu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "b6748bcf-ef4c-4f47-e687-00eeab0903dd"
      },
      "source": [
        "# Tabulate the PorterStemmer Results\r\n",
        "\r\n",
        "## paragraph\r\n",
        "paragraph = \"One of the most challenging and revolutionary things artificial intelligence (AI) can do is speak, write, listen, and understand human language. Natural language processing (NLP) is a form of AI that extracts meaning from human language to make decisions based on the information.\"\r\n",
        "\r\n",
        "## Remove unnecessary things\r\n",
        "pattern = r'[{}:<>?<,./\\|()!@#$%^&*_+-=~`;\\']'\r\n",
        "clean_paragraph = re.sub(pattern, \"\", paragraph)\r\n",
        "\r\n",
        "## Lowercase words and tokenize\r\n",
        "lowercase_words = {word:word.lower() for word in clean_paragraph.split(\" \")}\r\n",
        "\r\n",
        "## Removing stopwords\r\n",
        "cleaner_paragraph = [original_word for original_word in lowercase_words.keys() if not lowercase_words[original_word] in stopwords.words('english')]\r\n",
        "\r\n",
        "## Convert the list to a pandas DataFrame\r\n",
        "porterstemmer_df = pd.DataFrame(cleaner_paragraph, columns=['word'])\r\n",
        "\r\n",
        "## Add column for original word a\r\n",
        "porterstemmer_df['lowercase_word'] = porterstemmer_df.word.apply(lambda word: lowercase_words[word])\r\n",
        "ps = PorterStemmer()\r\n",
        "porterstemmer_df['stem'] = porterstemmer_df.lowercase_word.apply(lambda word: ps.stem(word))\r\n",
        "porterstemmer_df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>lowercase_word</th>\n",
              "      <th>stem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One</td>\n",
              "      <td>one</td>\n",
              "      <td>one</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>challenging</td>\n",
              "      <td>challenging</td>\n",
              "      <td>challeng</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>revolutionary</td>\n",
              "      <td>revolutionary</td>\n",
              "      <td>revolutionari</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>things</td>\n",
              "      <td>things</td>\n",
              "      <td>thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>artificial</td>\n",
              "      <td>artificial</td>\n",
              "      <td>artifici</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>intelligence</td>\n",
              "      <td>intelligence</td>\n",
              "      <td>intellig</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AI</td>\n",
              "      <td>ai</td>\n",
              "      <td>ai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>speak</td>\n",
              "      <td>speak</td>\n",
              "      <td>speak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>write</td>\n",
              "      <td>write</td>\n",
              "      <td>write</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>listen</td>\n",
              "      <td>listen</td>\n",
              "      <td>listen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>understand</td>\n",
              "      <td>understand</td>\n",
              "      <td>understand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>human</td>\n",
              "      <td>human</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>language</td>\n",
              "      <td>language</td>\n",
              "      <td>languag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Natural</td>\n",
              "      <td>natural</td>\n",
              "      <td>natur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>processing</td>\n",
              "      <td>processing</td>\n",
              "      <td>process</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>NLP</td>\n",
              "      <td>nlp</td>\n",
              "      <td>nlp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>form</td>\n",
              "      <td>form</td>\n",
              "      <td>form</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>extracts</td>\n",
              "      <td>extracts</td>\n",
              "      <td>extract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>meaning</td>\n",
              "      <td>meaning</td>\n",
              "      <td>mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>make</td>\n",
              "      <td>make</td>\n",
              "      <td>make</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>decisions</td>\n",
              "      <td>decisions</td>\n",
              "      <td>decis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>based</td>\n",
              "      <td>based</td>\n",
              "      <td>base</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>information</td>\n",
              "      <td>information</td>\n",
              "      <td>inform</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             word lowercase_word           stem\n",
              "0             One            one            one\n",
              "1     challenging    challenging       challeng\n",
              "2   revolutionary  revolutionary  revolutionari\n",
              "3          things         things          thing\n",
              "4      artificial     artificial       artifici\n",
              "5    intelligence   intelligence       intellig\n",
              "6              AI             ai             ai\n",
              "7           speak          speak          speak\n",
              "8           write          write          write\n",
              "9          listen         listen         listen\n",
              "10     understand     understand     understand\n",
              "11          human          human          human\n",
              "12       language       language        languag\n",
              "13        Natural        natural          natur\n",
              "14     processing     processing        process\n",
              "15            NLP            nlp            nlp\n",
              "16           form           form           form\n",
              "17       extracts       extracts        extract\n",
              "18        meaning        meaning           mean\n",
              "19           make           make           make\n",
              "20      decisions      decisions          decis\n",
              "21          based          based           base\n",
              "22    information    information         inform"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnxKrcIz99V3",
        "outputId": "7d15779e-8431-4263-ce3b-2fb94d1899b7"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNYRi9b2-tX2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}